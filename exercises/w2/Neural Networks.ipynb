{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1fc1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571e1973",
   "metadata": {},
   "source": [
    "<br/> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131cc8ba",
   "metadata": {},
   "source": [
    "## Överblick\n",
    "\n",
    "**Nu ska vi träna Neurala Nätverk och få lite praktiskt erfarenhet av Hyperparameters**\n",
    "\n",
    "Vi kommer bygga och träna Neurala Nätverk för att lösa regressionsproblem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ac78d1",
   "metadata": {},
   "source": [
    "**GRAFIKKORTSACCELERATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67d8997",
   "metadata": {},
   "source": [
    "Kolla om GPU-acceleration är tillgänligt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd6a544",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Available device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8697d4",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2ed956",
   "metadata": {},
   "source": [
    "Vi ska använda oss av Seol bicycle demand data, och träna modeller att kunna predicta... just det, bicycle demand per dag.  \n",
    "\n",
    "Datat kommer från https://archive.ics.uci.edu/dataset/560/seoul+bike+sharing+demand\n",
    "\n",
    "**Som vanligt går ni in där för att läsa på mer om respektive feature!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8592eda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_df = pd.read_csv('SeoulBikeData.csv', encoding='latin1')\n",
    "demand_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63ea45d",
   "metadata": {},
   "source": [
    "Nästan alla features ser rätt nice ut och värda att behålla, men vi kommer göra en förenkling. Vi tar för givet att det endast spelar roll huruvida aktuell dag är en helgdag eller inte. Dvs, vi bryr oss inte om exakt vilken dag det är. Vi kan således ta bort kolumnen 'Date' eftersom att vi har en annan kolumn 'Holiday' som anger om det är helgdag eller ej.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416cf303",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_df = demand_df[demand_df.columns[1:]] # exludera första kolumnen (Date)\n",
    "demand_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8252b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd209a14",
   "metadata": {},
   "source": [
    "Nu återstår fyra kolumner kvar som vi behöver specialanpassa. Dels har vi Hour och Seasons, som både är kategoriska. Därefter har vi också Holiday och Functioning Day som är binära, men behöver omvandlas till siffor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ea6ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(demand_df['Holiday'].value_counts(), end = '\\n\\n')\n",
    "print(demand_df['Functioning Day'].value_counts(), end = '\\n\\n')\n",
    "print(demand_df['Seasons'].value_counts(), end = '\\n\\n')\n",
    "print(demand_df['Hour'].value_counts(), end = '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0c8c35",
   "metadata": {},
   "source": [
    "**Omvandla binära kolumner till 1/0.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5701d959",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_columns = ['Holiday', 'Functioning Day']\n",
    "\n",
    "for column in binary_columns:\n",
    "    \n",
    "    first_value = demand_df[column].unique()[0] # extrahera ett av de binära värdena\n",
    "    transformed_column = [1 if value == first_value else 0 for value in demand_df[column]]\n",
    "    \n",
    "    demand_df[column] = transformed_column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaed15e",
   "metadata": {},
   "source": [
    "**Kolumnen Hour**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87633c7c",
   "metadata": {},
   "source": [
    "Att direkt göra en One-Hot-encoding av Hour skulle ger oss alldeles för många nya kolumner. Istället konstruerar vi färre kategorier genom att klumpa ihop\n",
    "följande tidsspann\n",
    "\n",
    "0-5\n",
    "\n",
    "6-11\n",
    "\n",
    "12-17\n",
    "\n",
    "18-23\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7c5fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_hours = []                            # en lista som indikerar den nya kategorin för varje träningsinstans\n",
    "\n",
    "for hour in demand_df['Hour']:\n",
    "\n",
    "    if hour in range(0,6):\n",
    "        new_hours.append(0)\n",
    "\n",
    "    elif hour in range(6, 12):\n",
    "        new_hours.append(1)\n",
    "    \n",
    "    elif hour in range(12, 18):\n",
    "        new_hours.append(2)\n",
    "\n",
    "    elif hour in range(18, 24):\n",
    "        new_hours.append(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ac9a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_df['Hour'] = new_hours           # ersätt Hour med våra nya värden\n",
    "\n",
    "demand_df['Hour'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff337c0d",
   "metadata": {},
   "source": [
    "**Omvandla kategoriska kolumner med One Hot Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65930c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# För varje möjlig kategoriskt värde, loopa och konstruera en ny kolumn enligt ovan\n",
    "\n",
    "categorical_columns = ['Seasons', 'Hour']\n",
    "\n",
    "for column in categorical_columns:\n",
    "    for value in set(demand_df[column].values):\n",
    "    \n",
    "        onehotencode = [1 if x == value else 0 for x in demand_df[column]]\n",
    "        demand_df[value] = onehotencode\n",
    "    \n",
    "\n",
    "#slutligen, droppa orginalkolumnen som vi inte längre behöver    \n",
    "\n",
    "for column in categorical_columns:\n",
    "    demand_df = demand_df.drop(columns=[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c2a38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9056686",
   "metadata": {},
   "source": [
    "**Kontrolluppgift: Kolla så att datan är enligt förväntan, samt att alla kolumner nu är antingen int eller float**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589f5f3e",
   "metadata": {},
   "source": [
    "## Dela upp data i train/test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fae232",
   "metadata": {},
   "source": [
    "Vi väljer återigen proportionen 90% / 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31fd3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = demand_df.columns[0]\n",
    "feature_columns = demand_df.columns[1:]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(demand_df[feature_columns],         \n",
    "                                                    demand_df[target_column],\n",
    "                                                    test_size=0.1, \n",
    "                                                    random_state=42)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35864e93",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49498825",
   "metadata": {},
   "source": [
    "**Skala data**\n",
    "\n",
    "Nu  när vi delat upp data i train och test kan vi utföra de mer invasiva transformationerna, som att skala kolumner. **Kom dock ihåg att det är superviktigt att vi endast använder statistik från train split när vi transformerar, annars riskerar vi informationsläckage!** \n",
    "\n",
    "Det enda vi egentligen behöver skala om feature kolumnerna så att samtliga värden, till absolutbeloppet, inte blir särskilt mycket större än 1. Kikar vi lite snabbt på vår data så ser vi att så inte är fallet.\n",
    "\n",
    "Vi återanvänder vårt trick för att åstadkomma detta: att helt enkelt dela respektive kolumn, med det (till absolutbeloppet) högsta värdet. Då kommer samtliga värden skalas ner, och det högsta värdet i respektive kolumn vara (i absolut värde) 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fdc69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "for column in feature_columns:                               # iterera över alla input features\n",
    "    \n",
    "    highest_value = max(np.abs(x_train[column]))    # hitta det, till absolutbeloppet, högsta värdet i aktuella kolumn i x_train\n",
    "    \n",
    "    \n",
    "    # dela nu aktuell kolumn i x_train med det nyfunna högsta värdet\n",
    "    \n",
    "    x_train[column] = x_train[column] / highest_value \n",
    "    \n",
    "    # dela nu även motsvarande kolumn i x_test med SAMMA nyfunna högsta värde (från x_train)\n",
    "    \n",
    "    x_test[column] = x_test[column] / highest_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5c2faa",
   "metadata": {},
   "source": [
    "**KONTROLLUPPGIFT: Kolla så att vi åstadkommit transformationerna vi eftersökte** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d92c25d",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb59da0",
   "metadata": {},
   "source": [
    "**Omvandla till Tensor**\n",
    "\n",
    "Nu när siffrorna ser bra ut återstår det att omvandla till datatypen Tensor (optimal för PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfe4bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.from_numpy(np.array(x_train)).type(torch.FloatTensor)\n",
    "y_train = torch.from_numpy(np.array(y_train)).type(torch.FloatTensor).reshape([-1,1])\n",
    "\n",
    "x_test = torch.from_numpy(np.array(x_test)).type(torch.FloatTensor)\n",
    "y_test = torch.from_numpy(np.array(y_test)).type(torch.FloatTensor).reshape([-1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445840f7",
   "metadata": {},
   "source": [
    "**Ange för PyTorch att förbereda datan för GPU-acceleration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1573a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "\n",
    "x_test = x_test.to(device)\n",
    "y_test = y_test.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f39b4b4",
   "metadata": {},
   "source": [
    "**Zippa ihop vår träning- och testdata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f763276",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = list(zip(x_train, y_train))             # lägg ihop träningsdatan så att vi direkt kan skicka in i dataloader\n",
    "test_set = list(zip(x_test, y_test))                   # ditto för testdatan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f959fe74",
   "metadata": {},
   "source": [
    "<br/> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741e647f",
   "metadata": {},
   "source": [
    "## Skapa ett Neuralt Nätverk för regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3411a27",
   "metadata": {},
   "source": [
    "<br/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc940ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 30)\n",
    "        self.fc2 = nn.Linear(30, 30)\n",
    "        self.fc3 = nn.Linear(30, 1)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "                  \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9618c946",
   "metadata": {},
   "source": [
    " <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4590009",
   "metadata": {},
   "source": [
    "**Skapa en instans**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053bc182",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_size = 18                                    # vad ska input_size vara?\n",
    "\n",
    "model = NeuralNetwork(input_size)\n",
    "model = model.to(device)                         # vi skickar över modellen till gpu - om tillgänglig\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c32d1b1",
   "metadata": {},
   "source": [
    "**Kontrollfråga: Hur måna parametrar har ditt neurala nätverk?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc6c92d",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aef532e",
   "metadata": {},
   "source": [
    "Låt oss testa vad vår initierade modell spottar ur sig för output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c635d8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 100                                     # välj här vilken sample som helst, ange ett giltigt värde amellan 0 och 7884\n",
    "\n",
    "sample_features = x_train[sample]                # extrahera features\n",
    "sample_class = y_train[sample]                   # extrahera class (1 eller 0)\n",
    "\n",
    "model_prediction = model(sample_features)        # predicta outcome\n",
    "\n",
    "print('True bicycle demand               :', sample_class.item())\n",
    "print('Vår models predict                :', model_prediction.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5bb457",
   "metadata": {},
   "source": [
    "**Kontrollfråga** Hur tolkar du resultatet ovan?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4874f0f4",
   "metadata": {},
   "source": [
    "<br/> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b19cb9",
   "metadata": {},
   "source": [
    "## Träna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d4c32c",
   "metadata": {},
   "source": [
    " <br/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8073b1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 18                    # vad ska input_size vara?\n",
    "batch_size = 16\n",
    "\n",
    "epochs = 20                      # default = 20\n",
    "learning_rate = 0.001             # default = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a72031c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "#    initera modell, loss_function, optimizer & dataloader\n",
    "\n",
    "\n",
    "#model = NeuralNetwork(input_size)\n",
    "model = model.to(device)                                  # förbered modellen för GPU\n",
    "\n",
    "optimizer = SGD(model.parameters(), lr = learning_rate)\n",
    "loss_function = torch.nn.L1Loss()\n",
    "\n",
    "train_dataloader = DataLoader(training_set,                 \n",
    "                              batch_size = batch_size,       \n",
    "                              shuffle=True)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "#    träna\n",
    "\n",
    "\n",
    "\n",
    "batch_train_losses = []\n",
    "\n",
    "epoch_train_losses = []\n",
    "epoch_evaluation_losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0\n",
    "    \n",
    "    for batch in train_dataloader:\n",
    "        \n",
    "        y_true = batch[1]\n",
    "        input_features = batch[0]\n",
    "        \n",
    "        y_pred=model(input_features)\n",
    "        loss=loss_function(y_pred, y_true)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch_loss = loss.item()\n",
    "        batch_train_losses.append(batch_loss)\n",
    "    \n",
    "    epoch_average_loss = np.average(batch_train_losses[-len(train_dataloader):])\n",
    "    epoch_train_losses.append(epoch_average_loss)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "#   evalueringssektion \n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    y_true = y_test\n",
    "    input_features = x_test\n",
    "    \n",
    "    y_pred = model(input_features)\n",
    "    loss = loss_function(y_pred, y_true)\n",
    "    \n",
    "    evaluation_loss = loss.item()\n",
    "    epoch_evaluation_losses.append(evaluation_loss)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "#   plotta resultat \n",
    "\n",
    "plt.plot(epoch_train_losses, label = 'train loss')\n",
    "plt.plot(epoch_evaluation_losses, label = 'test loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f48456",
   "metadata": {},
   "source": [
    "## Uppgifter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734fb6d4",
   "metadata": {},
   "source": [
    "<br/> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ff1a32",
   "metadata": {},
   "source": [
    "**1)**\n",
    "\n",
    "Vi har ändrat på vad vi plottar. Lägg märke till att train loss nu är smooth! \n",
    "\n",
    "Vad är det vi gjort?! Är det rimtligt att göra så?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48663f6",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0d276f",
   "metadata": {},
   "source": [
    "**2)**\n",
    "\n",
    "Titta på train- och test losskurvorna från körning ovan (med default inställningar). \n",
    "\n",
    "Hur tolkar du resultatet? Vad bör man göra i ett sånt här scenario?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b44bf0",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3f4b77",
   "metadata": {},
   "source": [
    "**3)**\n",
    "\n",
    "Hur ser nätverket ut som du precis tränat? Rita upp den."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e047e35b",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da10c4c",
   "metadata": {},
   "source": [
    "**4)**\n",
    "\n",
    "Vi ska nu utföra en random search av hyperparameters, och vi ska endast göra detta över hyperparametern antal_neurons_per_layer.\n",
    "\n",
    "Observera följande lista\n",
    "\n",
    "antal_neurons_per_layer = [1, 5, 10, 20, 30, 50, 100]\n",
    "\n",
    "Gör en loop och träna nu ett nätverk med dessa värden på antal neuroner per lager.\n",
    "\n",
    "Bygg och träna samtliga nätverk med \n",
    "\n",
    "antal_lager =  4\n",
    "\n",
    "batch_size = 6\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "Vad drar du för slutsats?\n",
    "\n",
    "\n",
    "\n",
    "**OBS, ibland kan det se ut som att nätverket inte lärt sig något alls. Och så kan det vara, vi hade otur med matematiken helt enkelt. Stora nätverk kan ibland ta mer/mindre tid att komma igång att lära sig. Testa köra igen, och hoppas på lite mer tur! Du kanske också kan testa öka antal epoker.**\n",
    "\n",
    "**Vi kommer lära oss strategier för att motverka detta vid ett senare skede**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0e7739",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0369c3",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
