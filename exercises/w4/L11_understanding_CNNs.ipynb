{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Välkomna till denna MYCKET viktiga gruppuppgift!\n",
    " \n",
    "Er utmaning är att gå igenom följande CNN-class nedan, och sedan förstå varenda steg i forward()-metoden.\n",
    " \n",
    "Specifikt vill jag att ni förstår input- och output size för varje steg. Till er hjälp har ni redan svaren på input- och output för varje steg, men ni ska förstår *varför* det blir som det blir.\n",
    " \n",
    "Ni har också tillgång till PDF:er som vi gått igenom tillsammans. Gå igenom tillsammans, om så behövs!\n",
    " \n",
    "Diskutera i grupp steg-för-steg! Anteckna/rita om ni behöver för att förklara för era kamrater.\n",
    " \n",
    "**bonus 1** om ni hinner bli klara: Hur många parametrar har varje layer? Hur många parametrar har nätverket totalt?\n",
    "Kan ni komma fram till en formel för antalet parametrar per lager?\n",
    " \n",
    "**bonus 2**: Leta runt på nätet efter en grym visualisering av filter-aktiveringar. Visa upp för klassen!\n",
    " \n",
    " \n",
    "**Förutsättningar**\n",
    " \n",
    "Anta att vi jobbar med ett dataset med RGB-bilder av storleken 28x28x3, och att vi försöker lösa ett multiclass-problem med 10 möjliga klasser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "CNNModel nedan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3), padding='same')\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding='same')\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), padding='same')\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "        self.flat = nn.Flatten()\n",
    "\n",
    "        # Adjust the input size for fc4 based on the output of the final pooling layer\n",
    "        self.fc4 = nn.Linear(3 * 3 * 64, 512)\n",
    "        self.fc5 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):                # PARAMETERS\n",
    "        # Input = 28 x 28 x 3            # CNN\n",
    "        x = self.relu(self.conv1(x))     # in_channels * out_channels * kernel_width * kernel_height + bias\n",
    "        # Output = 28 x 28 x 32          #     3       *     32     *     3      *     3             +  32  = 864 + 32 = 896 parameters\n",
    "\n",
    "        # Input = 28 x 28 x 32           # POOLING\n",
    "        x = self.pool(x)                 # ((input_size_w - kernel_size_w + 2 * padding) / stride) + 1 = output_size_w\n",
    "        # Output = 14 x 14 x 32          # (28 - 2 + 2 * 0) / 2 + 1 = 14\n",
    "\n",
    "        # Input = 14 x 14 x 32\n",
    "        x = self.relu(self.conv2(x))     # in_channels * out_channels * kernel_width * kernel_height + bias\n",
    "        # Output = 14 x 14 x 64          #     32      *     64     *     3      *     3             +  64  = 18432 + 64 = 18 496 parameters\n",
    "\n",
    "        # Input = 14 x 14 x 64\n",
    "        x = self.pool(x)\n",
    "        # Output = 7 x 7 x 64\n",
    "\n",
    "        # Input = 7 x 7 x 64\n",
    "        x = self.relu(self.conv3(x))     # in_channels * out_channels * kernel_width * kernel_height + bias\n",
    "        # Output = 7 x 7 x 64            #     64      *     64     *      3      *         3        +  64  = 36 864 + 64 = 36 928 parameters\n",
    "                                     \n",
    "        # Input = 7 x 7 x 64\n",
    "        x = self.pool(x)                 # ((input_size_w - kernel_size_w + 2 * padding) / stride) + 1 = output_size_w\n",
    "        # Output = 3 x 3 x 64                   7        -      2        + 2 *    0     /    2     + 1 =       3\n",
    "\n",
    "        # NOTERA OVAN ATT POOL HOPPAR ÖVER ETT PAR PIXLAR, OM INTE DET ÄR JÄMNT ANTAL\n",
    "      \n",
    "        # Flatten the tensor\n",
    "        # Input = 3 x 3 x 64\n",
    "        x = self.flat(x)\n",
    "        # Output = 576 (3*3*64)\n",
    "\n",
    "        # Input = 576\n",
    "        x = self.relu(self.fc4(x))        # in_channels * out_channels + bias\n",
    "        # Output = 512                    #     576     *    512       + 512 = 295 424 parameters\n",
    "\n",
    "        # Input = 512\n",
    "        x = self.fc5(x)              \n",
    "        # Output = 10\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer to bonus 1\n",
    "**Parameters per convolutional layer**\n",
    "\n",
    "out_channels * (in_channels * kernel_width * kernel_height + 1) \n",
    "\n",
    "**Parameters per fully connected layer**\n",
    "\n",
    "out_channels * (in_channels + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNModel(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (relu): ReLU()\n",
      "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc4): Linear(in_features=576, out_features=512, bias=True)\n",
      "  (fc5): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = CNNModel()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNNModel                                 [1, 10]                   --\n",
       "├─Conv2d: 1-1                            [1, 32, 28, 28]           896\n",
       "├─ReLU: 1-2                              [1, 32, 28, 28]           --\n",
       "├─MaxPool2d: 1-3                         [1, 32, 14, 14]           --\n",
       "├─Conv2d: 1-4                            [1, 64, 14, 14]           18,496\n",
       "├─ReLU: 1-5                              [1, 64, 14, 14]           --\n",
       "├─MaxPool2d: 1-6                         [1, 64, 7, 7]             --\n",
       "├─Conv2d: 1-7                            [1, 64, 7, 7]             36,928\n",
       "├─ReLU: 1-8                              [1, 64, 7, 7]             --\n",
       "├─MaxPool2d: 1-9                         [1, 64, 3, 3]             --\n",
       "├─Flatten: 1-10                          [1, 576]                  --\n",
       "├─Linear: 1-11                           [1, 512]                  295,424\n",
       "├─ReLU: 1-12                             [1, 512]                  --\n",
       "├─Linear: 1-13                           [1, 10]                   5,130\n",
       "==========================================================================================\n",
       "Total params: 356,874\n",
       "Trainable params: 356,874\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 6.44\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 0.33\n",
       "Params size (MB): 1.43\n",
       "Estimated Total Size (MB): 1.77\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model, (1, 3, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
