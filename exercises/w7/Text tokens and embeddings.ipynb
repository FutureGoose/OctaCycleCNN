{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding LLMs and Transformers: Tokenization and Embeddings\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Large Language Models (LLMs), like GPT or BERT, are advanced AI models designed to understand and generate natural language. \n",
    "\n",
    "They rely on the **Transformer architecture**, a revolutionary approach that has reshaped Natural Language Processing (NLP).\n",
    "\n",
    "Before diving into how transformers work, it is essential to understand the foundational concepts:\n",
    "1. **Tokenization**: How text is broken into smaller units for the model to process.\n",
    "2. **Embeddings**: How tokens are represented as numerical vectors.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "### What is Tokenization?\n",
    "\n",
    "Tokenization is the process of splitting text into smaller units called **tokens**. Tokens could be:\n",
    "- **Words**: `\"The quick brown fox\"` ‚Üí `[\"The\", \"quick\", \"brown\", \"fox\"]`\n",
    "- **Subwords**: `\"unbelievable\"` ‚Üí `[\"un\", \"believable\"]`\n",
    "- **Characters**: `\"hello\"` ‚Üí `[\"h\", \"e\", \"l\", \"l\", \"o\"]`\n",
    "\n",
    "### Why Tokenize?\n",
    "\n",
    "Models work with numbers, not raw text. Tokenization converts raw text into numerical data that a model can process.\n",
    "\n",
    "### Types of Tokenizers\n",
    "1. **Word-based Tokenizer**: Splits at spaces and punctuation (naive but fast).\n",
    "2. **Character-based Tokenizer**: Breaks text into individual characters (useful for non-Latin scripts).\n",
    "3. **Subword-based Tokenizer**: Used in modern LLMs (e.g., Byte Pair Encoding, WordPiece). \n",
    "   - Balances vocabulary size and token granularity by splitting into common subwords.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Code Example: Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Tokenization Example\n",
    "text = \"Transformers are amazing! ü§Ø AIJId878vs¬§13\"\n",
    "\n",
    "# Naive word-based tokenizer\n",
    "tokens = text.split()\n",
    "print(\"Word-based Tokens:\", tokens)\n",
    "\n",
    "# Character-based tokenizer\n",
    "char_tokens = list(text)\n",
    "print(\"Character-based Tokens:\", char_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Hugging Face Tokenizer (Subword-based)\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load a pretrained tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenize the text\n",
    "subword_tokens = tokenizer.tokenize(text)\n",
    "print(\"Subword Tokens:\", subword_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output\n",
    "\n",
    "After running the code above, you will see:\n",
    "- **Word-based Tokens**: `['Transformers', 'are', 'amazing!']`\n",
    "- **Character-based Tokens**: `['T', 'r', 'a', 'n', ...]`\n",
    "- **Subword-based Tokens**: `['transformers', 'are', 'amazing', '!']`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping Tokens to Embeddings\n",
    "\n",
    "**What Does \"Mapping Tokens to Embeddings\" Mean?**\n",
    "\n",
    "Once the text is tokenized, the tokens are still symbolic representations (e.g., `['transformers', 'are']`). \n",
    "\n",
    "The model cannot process these directly because neural networks operate on numerical data. To enable computation:\n",
    "\n",
    "1. Tokens are first **mapped to unique IDs** using a **vocabulary**.\n",
    "2. These IDs are then mapped to their corresponding embeddings using an **embedding matrix**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Step 1: Token-to-ID Mapping**\n",
    "\n",
    "- Each token has a unique integer ID, assigned by the tokenizer.\n",
    "- The tokenizer's vocabulary is a lookup table mapping tokens to IDs.\n",
    "\n",
    "**Code Example: Token-to-ID Mapping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load a pretrained tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenize the text\n",
    "#text = \"ÿ≥ÿßÿ±ÿ© ŸáŸä ŸÅŸä ŸÉŸÖÿ®ŸàÿØŸäÿß ÿ£Ÿàÿ™ÿ¥ ÿ¥ŸäŸÑÿßÿ±\"\n",
    "text = \"Transformers are amazing!\"\n",
    "tokens = tokenizer.tokenize(text)\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "print(\"Tokens:\", tokens)\n",
    "print(\"Token IDs:\", token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Mapping IDs to Embeddings**\n",
    "\n",
    "The model uses an embedding matrix (a large table) where:\n",
    "- Rows represent tokens in the vocabulary.\n",
    "- Columns represent dimensions of the embedding (e.g., 768 in BERT).\n",
    "\n",
    "A token ID is used as an index to retrieve its corresponding row in the embedding matrix.\n",
    "\n",
    "**How It Works:**\n",
    "\n",
    "- Assume the vocabulary size is $V$ (e.g., 30,000) and the embedding size is $D$ (e.g., 768).\n",
    "- The embedding matrix is then a $V \\times D$ matrix.\n",
    "- For each token ID, the model retrieves the corresponding row as the embedding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Example embedding matrix (vocab_size=5, embedding_dim=3 for simplicity)\n",
    "vocab_size = 5\n",
    "embedding_dim = 3\n",
    "embedding_matrix = torch.randn(vocab_size, embedding_dim)\n",
    "\n",
    "print(\"Embedding Matrix:\\n\", embedding_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example token IDs\n",
    "token_ids = torch.tensor([0, 3, 4])  # Simulated token IDs\n",
    "print(f'token_ids: {token_ids}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve embeddings\n",
    "embeddings = embedding_matrix[token_ids]\n",
    "print(\"Retrieved Embeddings:\\n\", embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained Models: Token Mapping with Embeddings\n",
    "\n",
    "In real-world models like BERT, the embedding matrix is trained to represent meaningful relationships between tokens.\n",
    "\n",
    "**Code Example: Mapping with a Pretrained Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Load tokenizer and model\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "#model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Input text\n",
    "text = \"Transformers are amazing!\"\n",
    "\n",
    "# Tokenize and get token IDs\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")  # Token IDs are in inputs['input_ids']\n",
    "token_ids = inputs[\"input_ids\"]\n",
    "\n",
    "# Retrieve the embedding matrix\n",
    "embedding_layer = model.embeddings.word_embeddings\n",
    "\n",
    "# Get embeddings for input tokens\n",
    "embeddings = embedding_layer(token_ids)\n",
    "\n",
    "print(\"Token IDs:\", token_ids)\n",
    "print(\"Embeddings Shape:\", embeddings.shape)  # (batch_size, seq_len, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.reshape(6,-1)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
