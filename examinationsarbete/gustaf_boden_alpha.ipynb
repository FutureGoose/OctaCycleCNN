{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# add deep_learning_tools path\n",
    "package_root = Path.cwd().parent / 'deep_learning_tools'\n",
    "sys.path.append(str(package_root))\n",
    "\n",
    "# reusable parameters\n",
    "dataset_name = 'CIFAR10'\n",
    "data_root = Path.cwd().parent / 'data'\n",
    "\n",
    "# import everything except architectures\n",
    "from src import prepare_datasets, ModelTrainer, accuracy, MetricsPlotter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import MultiStepLR, OneCycleLR, StepLR\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\u001b[38;5;40mUsing FP16 (half precision) training\u001b[0m\n",
      "torch.Size([968])                                                    \n",
      "968\n",
      "tensor(501, device='cuda:0')\n",
      "501\n",
      "<class 'int'>\n",
      "Validate:   0%|          | 0/5 [00:00<?, ?it/s]torch.Size([1024])\n",
      "1024\n",
      "tensor(547, device='cuda:0')\n",
      "547\n",
      "<class 'int'>\n",
      "Validate:   0%|          | 0/5 [00:00<?, ?it/s, loss=1.2793, accuracy=53.42%]torch.Size([1024])\n",
      "1024\n",
      "tensor(547, device='cuda:0')\n",
      "547\n",
      "<class 'int'>\n",
      "Validate:  20%|██        | 1/5 [00:00<00:01,  2.60it/s, loss=1.2793, accuracy=53.42%]torch.Size([1024])\n",
      "1024\n",
      "tensor(559, device='cuda:0')\n",
      "559\n",
      "<class 'int'>\n",
      "Validate:  20%|██        | 1/5 [00:00<00:01,  2.60it/s, loss=1.2705, accuracy=54.59%]torch.Size([1024])\n",
      "1024\n",
      "tensor(559, device='cuda:0')\n",
      "559\n",
      "<class 'int'>\n",
      "torch.Size([1024])\n",
      "1024\n",
      "tensor(531, device='cuda:0')\n",
      "531\n",
      "<class 'int'>\n",
      "Validate:  20%|██        | 1/5 [00:00<00:01,  2.60it/s, loss=1.2832, accuracy=51.86%]torch.Size([1024])\n",
      "1024\n",
      "tensor(531, device='cuda:0')\n",
      "531\n",
      "<class 'int'>\n",
      "torch.Size([1024])\n",
      "1024\n",
      "tensor(523, device='cuda:0')\n",
      "523\n",
      "<class 'int'>\n",
      "Validate:  20%|██        | 1/5 [00:00<00:01,  2.60it/s, loss=1.2998, accuracy=51.07%]torch.Size([1024])\n",
      "1024\n",
      "tensor(523, device='cuda:0')\n",
      "523\n",
      "<class 'int'>\n",
      "torch.Size([904])\n",
      "904\n",
      "tensor(470, device='cuda:0')\n",
      "470\n",
      "<class 'int'>\n",
      "Validate:  20%|██        | 1/5 [00:01<00:01,  2.60it/s, loss=1.3301, accuracy=51.99%]torch.Size([904])\n",
      "904\n",
      "tensor(470, device='cuda:0')\n",
      "470\n",
      "<class 'int'>\n",
      "\u001b[38;5;44m[epoch 01] train loss: 1.6038 | val loss: 1.2926 | accuracy: 52.59%\u001b[0m    \n",
      "\u001b[38;5;40mValidation loss decreased (inf --> 1.2926). Saving model.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from models.mod_eight_layer_conv_net.architecture import ModEightLayerConvNet\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=2, padding_mode='reflect'),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
    "])\n",
    "\n",
    "trainset, valset, testset = prepare_datasets(\n",
    "    dataset_name=dataset_name, \n",
    "    data_root=data_root,\n",
    "    transform_train=transform_train,\n",
    "    transform_val=transform_val,\n",
    "    normalize=False,\n",
    "    use_validation_split=True\n",
    ")\n",
    "\n",
    "def train_model(model, model_name, num_epochs=200):\n",
    "\n",
    "    max_lr = 0.1\n",
    "    div_factor = 5          # controls initial LR: higher = lower start (max_lr/div_factor = 0.1/5 = 0.02)\n",
    "    final_div_factor = 15   # controls decay speed: higher = faster decay (max_lr/final_div_factor = 0.1/15 ≈ 0.007)\n",
    "    initial_lr = max_lr / div_factor\n",
    "    \n",
    "    # adjust warmup length based on absolute epochs, not percentage\n",
    "    # absolute_warmup_epochs = 12\n",
    "    # pct_start = absolute_warmup_epochs / num_epochs  # dynamically calculated\n",
    "    pct_start = 0.23\n",
    "   \n",
    "    optimizer = SGD(\n",
    "        model.parameters(),\n",
    "        lr=initial_lr,\n",
    "        momentum=0.9,\n",
    "        weight_decay=0.01,\n",
    "    )\n",
    "\n",
    "    # calculate total steps\n",
    "    steps_per_epoch = math.ceil(len(trainset) / 1024)\n",
    "    total_steps = steps_per_epoch * num_epochs\n",
    "\n",
    "    scheduler = OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=max_lr,                     # (1) Peak learning rate\n",
    "        total_steps=total_steps,           # (2) Total number of training iterations\n",
    "        pct_start=pct_start,               # (3) Percentage of training spent in warmup\n",
    "        div_factor=div_factor,             # (4) Initial LR division factor  (Initial LR = max_lr/div_factor = 0.1/5 = 0.02)\n",
    "        final_div_factor=final_div_factor, # (5) Final LR division factor    (Final LR = max_lr/final_div_factor = 0.1/15 ≈ 0.007)\n",
    "        anneal_strategy='cos'              # (6) Type of annealing (default 'cos')\n",
    "    )\n",
    "    \n",
    "    trainer = ModelTrainer(\n",
    "        model=model,\n",
    "        device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "        loss_fn=nn.CrossEntropyLoss(),\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        batch_size=1024,\n",
    "        verbose=True,\n",
    "        save_metrics=False,\n",
    "        early_stopping_patience=5,\n",
    "        metrics=[accuracy],\n",
    "        log_dir=f\"logs/{model_name}\",\n",
    "        step_scheduler_batch=True,\n",
    "        run_karpathy_checks=False,\n",
    "        # logger_type=\"file\",\n",
    "\n",
    "    )\n",
    "    \n",
    "    trained_model = trainer.train(\n",
    "        training_set=trainset,\n",
    "        val_set=valset,\n",
    "        num_epochs=num_epochs\n",
    "    )\n",
    "    \n",
    "    return trainer\n",
    "\n",
    "model2 = ModEightLayerConvNet()\n",
    "trainer2 = train_model(model2, \"ModEightLayerConvNet\", num_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Eight Layer Conv Net\n",
    "\n",
    "#### Architecture Overview\n",
    "\n",
    "My EightLayerConvNet's backbone is somewhat inspired by VGG16 (16 layers), alternating convolutional layers with a kernel size of 3 and max pooling layers at the end of each block except for the last one. However, since we're working with CIFAR-10's 32x32 images rather than ImageNet's 224x224 images, most other architectural aspects differ significantly from the original VGG design.\n",
    "\n",
    "EightLayerConvNet has three convolutional blocks where each block contains only two convolutional layers, with the number of filters doubling after each block. I use AdaptiveAvgPool2d for global pooling in the final convolutional layer, followed by a fully connected layer with 512 neurons, a dropout layer, and a final linear output layer with 10 neurons. This architecture prioritizes efficient feature extraction while maintaining simplicity i.e. just enough layers to get the job done.\n",
    "\n",
    "I use BatchNorm2d with a momentum of 0.6 and ReLU activation functions with inplace=True. BatchNorm2d helps stabilize training and prevent overfitting. Since there's BatchNorm2d, the bias terms can be omitted in our convolutional layers—I'll explain why in the technical details further below.\n",
    "\n",
    "The convolutions use padding='same'. Our classifier consists of two fully connected layers: the first with 512 neurons (with bias) and the second with 10 neurons (without bias, since we're using cross-entropy loss with softmax). Lastly, weights are initialized using orthogonal initialization with gain=1.\n",
    "\n",
    "For training, I use:\n",
    "- Batch size: 1024\n",
    "- Initial learning rate: 0.1\n",
    "- SGD optimizer with momentum: 0.9\n",
    "- Weight decay: 0.01\n",
    "- MultiStepLR scheduler (milestones: [8, 13], gamma: 0.1)\n",
    "- Data augmentation: random cropping and horizontal flipping (inspired by various CIFAR-10 implementations, notably [pytorch-cifar](https://github.com/kuangliu/pytorch-cifar))\n",
    "\n",
    "Let's dive into some of the technical details that weren't covered in our course:\n",
    "\n",
    "\n",
    "#### Technical Deep Dive\n",
    "\n",
    "**BatchNorm2d - What and Why?**  \n",
    "BatchNorm was introduced in 2015 by Ioffe and Szegedy in their paper [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167). The idea is brilliantly simple: normalize the data not just at input but at each layer. This helps solve the \"internal covariate shift\" problem, where the distribution of each layer's inputs keeps changing during training.\n",
    "\n",
    "When using BatchNorm2d, we can set the bias parameter to false in convolutional layers. This is because BatchNorm2d's learnable parameters β and γ already handle the bias functionality, making the convolution layer's bias redundant. This optimization reduces computations without affecting model performance.\n",
    "\n",
    "**BatchNorm's Momentum - The Running Average**  \n",
    "According to [PyTorch's BatchNorm2d documentation](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html), the momentum parameter (0.6 in our case) is used differently than in optimizers. For running statistics, the update rule is:\n",
    "\n",
    "x_new = (1 - momentum) * x + momentum * x_t\n",
    "\n",
    "where x is our estimated statistic (mean or variance) and x_t is the new observed value. With momentum = 0.6, each update keeps 40% of the previous estimate and incorporates 60% of the new batch statistics. This helps maintain stable statistics while adapting to changes in the data distribution.\n",
    "\n",
    "**ReLU's inplace=True - Memory Efficiency**  \n",
    "The inplace parameter in ReLU is a memory optimization. When True, ReLU modifies its input tensor directly instead of creating a new one, saving memory during training.\n",
    "\n",
    "\n",
    "**AdaptiveAvgPool2d((1, 1)) - Global Feature Aggregation**  \n",
    "The AdaptiveAvgPool2d((1, 1)) layer performs global average pooling, reducing spatial dimensions to 1×1 while preserving the channel dimension. Each channel creates a summary of its spatial information into a single value - instead of having 64 values (8×8) per channel, we get their average as a global summary. This technique was popularized by the [Network In Network paper (Lin et al., 2013)](https://arxiv.org/abs/1312.4400) as a more parameter-efficient alternative to using multiple fully connected layers. It helps reduce overfitting and makes the network more robust to spatial translations, meaning the model becomes less sensitive to the exact position of objects within the image.\n",
    "\n",
    "**SGD with Momentum - Accelerated Optimization**  \n",
    "[Momentum](https://towardsdatascience.com/stochastic-gradient-descent-with-momentum-a84097641a5d) in SGD helps accelerate optimization by accumulating a running average of past gradients. \n",
    "\n",
    "Without momentum, the weight update is new_weight = old_weight - learning_rate * gradient.\n",
    "\n",
    "With momentum there's something called a velocity term. The update rule is then new_weight = old_weight - velocity, where velocity is:\n",
    "\n",
    "new_velocity = momentum * old_velocity + learning_rate * gradient.\n",
    "\n",
    "So momentum brings the accumulated effect of past gradient updates by carrying over the velocity term. This information helps the optimizer avoid being overly reactive to single batch gradients and accelerates convergence in smoother paths.\n",
    "\n",
    "**Weight Initialization - Orthogonal Initialization**  \n",
    "We initialize the convolutional and linear layer weights using [orthogonal initialization](https://medium.com/@decanbay/orthogonal-weight-initialization-in-pytorch-ac67d8721851) with gain=1. This technique, studied in [Saxe et al. (2013)](https://arxiv.org/abs/1312.6120), creates weight matrices whose columns are orthogonal to each other. Orthogonal matrices preserve input magnitudes during forward propagation, helping prevent vanishing gradients in deep networks. The bias of the first fully connected layer is initialized to zero, allowing the network to learn appropriate shifts based purely on the data distribution. We omit the bias in the final layer because we're using cross-entropy loss with softmax, where bias terms would be redundant since softmax is translation-invariant (shifting all logits by a constant doesn't change the probabilities).\n",
    "\n",
    "**Augmentation - Cropping and Flipping**  \n",
    "The augmentation techniques we use include random cropping and horizontal flipping. These are common methods for data augmentation and are fundamental concepts demonstrated in PyTorch's documentation under the section titled [\"I just want to do image classification\"](https://pytorch.org/vision/main/auto_examples/transforms/plot_transforms_getting_started.html#sphx-glr-auto-examples-transforms-plot-transforms-getting-started-py). This augmentation is particularly prevalent for CIFAR-10 and has been empirically shown to enhance performance. Random cropping allows the model to learn object recognition across different spatial contexts, while horizontal flipping enables the model to generalize across symmetrical orientations.\n",
    "\n",
    "#### Model Performance and Next Steps\n",
    "My process for building this model was iterative, taking one step at a time and adding one thing at a time, getting slightly better each time. The model was, in its final state, able to periodically reach around 87-88% accuracy on the validation set, but sometimes struggled to reach 84%. It was quite unstable, with early stopping getting triggered quite often before it reached the set amount of epochs.\n",
    "\n",
    "Early stopping wasn't just set because of impatience (okay, maybe a little bit), but mainly because I noticed a clear pattern - if the model showed no improvement for 2-5 epochs, it wouldn't improve even after 100 epochs. It would just get stuck in a bad local minimum. I verified this through multiple longer training runs, so the early stopping actually saved a lot of computation time.\n",
    "\n",
    "I started to mess with the learning rates and noticed in the loss curves that, besides the hockey stick in the beginning, there were some early issues - a \"bump\" that the model needed to get over around epoch 5-8. I lowered the learning rate there, and then noticed another bump around epoch 13. Lowering it there also made it possible for the model to continue training to around epoch 20 before things got boring...most of the time.\n",
    "\n",
    "At this point, the model could reach about 85% accuracy, but it varied from session to session: sometimes early stopping was triggered before 85%, sometimes it took 40 epochs to reach say 87%. My goal now was clear: reach 90%+ accuracy, reliably in 20 epochs or less.\n",
    "\n",
    "After the process of tinkering with the learning rate, I started to notice some patterns in the model's performance that indicated I should be able to tune it in a more sophisticated way than just reducing the learning rate at certain epochs. This brings us to our next model, which, thanks to a resource I found, gave me the idea to use a \"triangle\" learning rate scheduler. This solved exactly that problem. Instead of analyzing this model much further, let's checkout the class accuracies and then swiftly move on to my main and best performing model when it comes to both training speed and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.eight_layer_conv_net.architecture import EightLayerConvNet\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=2),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
    "])\n",
    "\n",
    "trainset, valset, testset = prepare_datasets(\n",
    "    dataset_name=dataset_name, \n",
    "    data_root=data_root,\n",
    "    transform_train=transform_train,\n",
    "    transform_val=transform_val,\n",
    "    normalize=False,\n",
    "    use_validation_split=True,\n",
    ")\n",
    "\n",
    "def train_model(model, model_name, num_epochs=200):\n",
    "    optimizer = SGD(\n",
    "        model.parameters(),\n",
    "        lr=0.1,\n",
    "        momentum=0.9,\n",
    "        weight_decay=0.01,\n",
    "    )\n",
    "    \n",
    "    scheduler = MultiStepLR(\n",
    "        optimizer,\n",
    "        milestones=[8, 13],\n",
    "        gamma=0.1\n",
    "    )\n",
    "    \n",
    "    trainer = ModelTrainer(\n",
    "        model=model,\n",
    "        device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "        loss_fn=nn.CrossEntropyLoss(),\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        batch_size=1024,\n",
    "        verbose=True,\n",
    "        save_metrics=False,\n",
    "        early_stopping_patience=3,\n",
    "        early_stopping_delta=1e-4,\n",
    "        metrics=[accuracy],\n",
    "        log_dir=f\"logs/{model_name}\",\n",
    "        logger_type=\"file\",\n",
    "    )\n",
    "    \n",
    "    trained_model = trainer.train(\n",
    "        training_set=trainset,\n",
    "        val_set=valset,\n",
    "        num_epochs=num_epochs\n",
    "    )\n",
    "    \n",
    "    return trainer\n",
    "\n",
    "model1 = EightLayerConvNet()\n",
    "trainer1 = train_model(model1, \"EightLayerConvNet\", num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_1 = trainer1.evaluate_on_test(test_set=testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Accuracies\n",
    "\n",
    "This section displays the class accuracies as a reference point for the upcoming model, where we will conduct a more thorough error analysis. Without revealing too much, the errors of the next models are quite similar to those of this one – just significantly improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = test_results_1['true_labels']\n",
    "predictions = test_results_1['predictions']\n",
    "\n",
    "plotter = MetricsPlotter()\n",
    "ax = plotter.plot_class_accuracy(true_labels, predictions, testset.classes, dataset_name=\"CIFAR-10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Eight Layer Conv Net Modified\n",
    "\n",
    "### Model Overview\n",
    "\n",
    "Here we are with my model of choice. Using an ancient GPU, the Nvidia RTX 2070 SUPER from 2019, we can consistently achieve a model with 91% accuracy in just 1.5 minutes by training it for less than 20 epochs. This model is very similar to the previous one, but it includes a few, albeit very important, modifications.\n",
    "\n",
    "Looking at the loss curves, we can see that our improved model doesn't have the same \"hockey stick\" shape as the previous model. This is because the learning rate scheduler is changed to a OneCycleLR scheduler. This scheduler is a more sophisticated learning rate scheduler that is able to take us from 84% accuracy to 91% accuracy in the same 20 epochs. Without going into too much detail, it basically means that instead of the learning rate just being reduced at certain epochs, it instead works like a triangle - starting at a low learning rate (called warmup, this addresses the hockey stick effect and stabilizes early training), increasing to a high learning rate, and then decreasing back to a low learning rate. This is inspired by [Keller Jordan](https://arxiv.org/pdf/2404.00498) which in turn is inspired by [tysam-code](https://github.com/tysam-code/hlb-CIFAR10). To learn more about this scheduler, read the inline comments in the code below or check out pytorch's [documentation](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.OneCycleLR.html). As a visual representation, the following diagram shows an approximation of how the learning rate changes over time in our training:\n",
    "\n",
    "**Learning Rate Schedule**\n",
    "\n",
    "```text\n",
    "Epoch 0:  lr = 0.02     (Initial LR = max_lr/div_factor)\n",
    "Epoch 2:  lr = 0.06     (Middle of warmup)\n",
    "Epoch 5:  lr = 0.1      (Peak LR, end of warmup)\n",
    "Epoch 12: lr = 0.05     (Middle of annealing)\n",
    "Epoch 20: lr = 0.0067   (Final LR = max_lr/final_div_factor)\n",
    "\n",
    "\n",
    "Learning Rate\n",
    "   ^\n",
    "   |\n",
    "0.1 -          /\\\n",
    "   |         /    \\\n",
    "   |       /        \\\n",
    "0.02-    /           \\\n",
    "   |   /               \\\n",
    "   | /                  \\\n",
    "   |                     \\\n",
    "0.0067                    \\\n",
    "   +-----------------------> Epochs\n",
    "   0   5    10    15    20\n",
    "```\n",
    "\n",
    "**Other Modifications**\n",
    "\n",
    "While the learning rate was the most pivotal change, there were also a few other modifications:\n",
    "\n",
    "- Enhanced the orthogonal weight initialization by changing the gain factor from 1 to $\\sqrt{2}$ and noticed a small improvement in performance and convergence speed.\n",
    "- Padding mode for RandomCrop was changed to reflect, training got more stable.\n",
    "- step_scheduler_batch=True was added to the ModelTrainer. This allows the learning rate scheduler to be updated after each batch instead of after each epoch. This was a prerequisite for the OneCycleLR scheduler to work (see the [documentation](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.OneCycleLR.html)).\n",
    "\n",
    "Model performance and error analysis is found in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.mod_eight_layer_conv_net.architecture import ModEightLayerConvNet\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=2, padding_mode='reflect'),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
    "])\n",
    "\n",
    "trainset, valset, testset = prepare_datasets(\n",
    "    dataset_name=dataset_name, \n",
    "    data_root=data_root,\n",
    "    transform_train=transform_train,\n",
    "    transform_val=transform_val,\n",
    "    normalize=False,\n",
    "    use_validation_split=True\n",
    ")\n",
    "\n",
    "def train_model(model, model_name, num_epochs=200):\n",
    "\n",
    "    max_lr = 0.1\n",
    "    div_factor = 5          # controls initial LR: higher = lower start (max_lr/div_factor = 0.1/5 = 0.02)\n",
    "    final_div_factor = 15   # controls decay speed: higher = faster decay (max_lr/final_div_factor = 0.1/15 ≈ 0.007)\n",
    "    initial_lr = max_lr / div_factor\n",
    "    \n",
    "    # adjust warmup length based on absolute epochs, not percentage\n",
    "    # absolute_warmup_epochs = 12\n",
    "    # pct_start = absolute_warmup_epochs / num_epochs  # dynamically calculated\n",
    "    pct_start = 0.23\n",
    "   \n",
    "    optimizer = SGD(\n",
    "        model.parameters(),\n",
    "        lr=initial_lr,\n",
    "        momentum=0.9,\n",
    "        weight_decay=0.01,\n",
    "    )\n",
    "\n",
    "    # calculate total steps\n",
    "    steps_per_epoch = math.ceil(len(trainset) / 1024)\n",
    "    total_steps = steps_per_epoch * num_epochs\n",
    "\n",
    "    scheduler = OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=max_lr,                     # (1) Peak learning rate\n",
    "        total_steps=total_steps,           # (2) Total number of training iterations\n",
    "        pct_start=pct_start,               # (3) Percentage of training spent in warmup\n",
    "        div_factor=div_factor,             # (4) Initial LR division factor  (Initial LR = max_lr/div_factor = 0.1/5 = 0.02)\n",
    "        final_div_factor=final_div_factor, # (5) Final LR division factor    (Final LR = max_lr/final_div_factor = 0.1/15 ≈ 0.007)\n",
    "        anneal_strategy='cos'              # (6) Type of annealing (default 'cos')\n",
    "    )\n",
    "    \n",
    "    trainer = ModelTrainer(\n",
    "        model=model,\n",
    "        device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "        loss_fn=nn.CrossEntropyLoss(),\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        batch_size=1024,\n",
    "        verbose=True,\n",
    "        save_metrics=False,\n",
    "        early_stopping_patience=float('inf'),\n",
    "        metrics=[accuracy],\n",
    "        log_dir=f\"logs/{model_name}\",\n",
    "        logger_type=\"file\",\n",
    "        step_scheduler_batch=True,\n",
    "\n",
    "    )\n",
    "    \n",
    "    trained_model = trainer.train(\n",
    "        training_set=trainset,\n",
    "        val_set=valset,\n",
    "        num_epochs=num_epochs\n",
    "    )\n",
    "    \n",
    "    return trainer\n",
    "\n",
    "model2 = ModEightLayerConvNet()\n",
    "trainer2 = train_model(model2, \"ModEightLayerConvNet\", num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_2 = trainer2.evaluate_on_test(test_set=testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Insights\n",
    "#### Class Accuracies\n",
    "\n",
    "Our analysis shows that cats, birds, and dogs have the lowest accuracy rates among all classes. Cats perform the worst with ~81% accuracy rate, while most other classes (excluding these three) achieve accuracies above 92%.\n",
    "\n",
    "To better understand our model's weakness with cats, we need to investigate what the model is confusing them with. This leads us to our next question: What specific patterns are causing the model to struggle with cat classification?\n",
    "\n",
    "To answer this, we need to examine the confusion matrix, which will provide more granular metrics. Several scenarios could explain this performance:\n",
    "1. The model might be producing false positives (e.g., incorrectly classifying dogs as cats)\n",
    "2. The model might be generating false negatives (e.g., missing actual cats and classifying them as other classes)\n",
    "\n",
    "Since accuracy alone cannot reveal these patterns, our next step is to analyze the confusion matrix for a detailed view of these misclassifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels_2 = test_results_2['true_labels']\n",
    "predictions_2 = test_results_2['predictions']\n",
    "\n",
    "plotter = MetricsPlotter()\n",
    "ax = plotter.plot_class_accuracy(true_labels_2, predictions_2, testset.classes, dataset_name=\"CIFAR-10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix\n",
    "\n",
    "The classification errors between cats and dogs appear to be bidirectional. The model frequently confuses cats with dogs and vice versa. \n",
    "\n",
    "As for birds, our third problematic class, the confusion is more distributed across various classes, though notably not with automobiles or trucks. \n",
    "\n",
    "While there are other patterns to explore, the cat/dog confusion stands out as the most significant issue. Given more time, we could investigate this further by implementing specialized data augmentations or more sophisticated convolution patterns to help the model better distinguish between these two classes. \n",
    "\n",
    "However, before considering such improvements, we need to deepen our understanding of the problem. Our next step is to examine the actual misclassified images to identify visual patterns that might explain the model's confusion. This analysis is crucial not only for understanding the current limitations but also for developing targeted solutions to improve the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized confusion matrix\n",
    "plotter.plot_confusion_matrix(\n",
    "    predictions=predictions_2,\n",
    "    true_labels=true_labels_2,\n",
    "    class_names=testset.classes,\n",
    "    dataset_name=\"CIFAR-10\",\n",
    "    normalize=True,\n",
    "    cmap='mako'\n",
    ")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Examples: Cats vs Dogs\n",
    "\n",
    "Looking at these comparison images, we can see interesting patterns in how our model handles cats and dogs. We've arranged the examples to show both misclassifications and correct predictions, and each time we run this code, we get new random examples to analyze.\n",
    "\n",
    "The confusion between cats and dogs makes sense when you look closely. Dogs with prominent, pointed ears often get mistaken for cats, and when cats take certain poses that are typically \"dog-like,\" the model gets confused. This isn't too surprising since they share many physical characteristics - both are four-legged animals that can look quite similar in certain poses.\n",
    "\n",
    "What's interesting is that when the model makes mistakes, it's often not very confident in its prediction. We see quite a few cases where the confidence is below 50%, which actually gives us hope - the model isn't confidently wrong, it's unsure. The main takeaways from looking through these examples are:\n",
    "- Pointy-eared dogs often trigger cat predictions\n",
    "- Cats in certain poses (especially with heads down) get classified as dogs\n",
    "- When image quality is poor, mistakes are more common, but that's not really the model's fault\n",
    "\n",
    "These insights could be valuable for future improvements to the model.\n",
    "\n",
    "As a side note, our third \"bonus model\" (which uses transfer learning with EfficientNet-B4) shows some interesting improvements in this area. It handles the dog-to-cat confusion much better - when it sees a dog, it much less often mistakes it for a cat. However, it's fascinating that even this more sophisticated model still struggles with cats, occasionally misclassifying them as dogs. This persistent cat-to-dog confusion suggests there might be something fundamentally challenging about certain cat features that even advanced architectures find tricky to handle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_2 = test_results_2['probabilities']\n",
    "\n",
    "# get images from test loader\n",
    "images = []\n",
    "for img, _ in test_results_2['test_loader']:\n",
    "    images.extend(img.numpy())\n",
    "images = np.array(images)\n",
    "\n",
    "# cat-dog confusion\n",
    "scenarios = [\n",
    "    {'true': 'cat', 'pred': 'dog', 'n': 3},  # cats predicted as dogs\n",
    "    {'true': 'dog', 'pred': 'cat', 'n': 3},  # dogs predicted as cats\n",
    "    {'true': 'cat', 'pred': 'cat', 'n': 3},  # correctly classified cats\n",
    "    {'true': 'dog', 'pred': 'dog', 'n': 3},  # correctly classified dogs\n",
    "]\n",
    "\n",
    "fig = plotter.plot_classification_examples(\n",
    "    predictions=predictions_2,\n",
    "    true_labels=true_labels_2,\n",
    "    probabilities=probabilities_2,\n",
    "    images=images,\n",
    "    class_names=testset.classes,\n",
    "    scenarios=scenarios\n",
    ")\n",
    "\n",
    "# fig.savefig('assets/classification_examples_cats_dogs.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Model: Transfer Learning EfficientNet-B4\n",
    "\n",
    "The choice of EfficientNet-B4 was initially inspired by [Josef Rynkiewicz's implementation](https://github.com/JosephRynkiewicz/CIFAR10), but it makes sense for our use case. B4 sits in the middle of the [EfficientNet](https://arxiv.org/pdf/1905.11946) family (B0-B7), providing a good balance between model capacity and computational requirements.\n",
    "\n",
    "We're using feature extraction from the last layer, which is suitable considering:\n",
    "- CIFAR-10 (50,000 images) is relatively small compared to ImageNet (1.2M images).\n",
    "- Both datasets handle similar object recognition tasks.\n",
    "- Pre-trained ImageNet features should transfer well to CIFAR-10.\n",
    "\n",
    "Here are some specifics:\n",
    "- Augmentation includes random cropping with a slightly smaller scale than evaluation. This reduces the computational load during training while still allowing for detailed evaluation.\n",
    "- Otherwise, we are using standard CIFAR-10 optimizer settings: a learning rate of 0.01 and momentum of 0.9; however, we apply a smaller weight decay since overfitting is less of a problem.\n",
    "- The scheduler is straightforward, with a step size of 10 and a gamma of 0.1.\n",
    "\n",
    "Besides these specifics, we're simply hitting the ground running with the pre-trained EfficientNet-B4 model, extracting features from CIFAR-10 and fine-tuning the output layer.\n",
    "\n",
    "### Reflection on EfficientNet Implementation\n",
    "\n",
    "I didn't create EfficientNet and can't take credit for it; that is, I won't consider it \"my best performing model.\" However, it was a great learning experience to implement it. I was definitely surprised that just importing this model from PyTorch and fine-tuning the output layer worked so well—outperforming pretty much any architecture I was able to build.\n",
    "\n",
    "What's even more baffling to me is that there are geniuses out there who can create models that achieve up to 94% accuracy, but still just train them solely on CIFAR-10 for only 3 seconds on a single GPU, or reach 96% accuracy after training for 27 seconds. I did spend some time trying to emulate some of these models, but it was just too much work for too little gain. (What is considered \"little\" and what is \"much\" is relative; a 2% increase can be significant. I also read that 94% is what is required to be considered as beating human performance.)\n",
    "\n",
    "I'm quite happy reaching around 92% accuracy on my own model, and it felt satisfying to be able to \"cheat\" like this and bump it up to approximately 98% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# add deep_learning_tools path\n",
    "package_root = Path.cwd().parent / 'deep_learning_tools'\n",
    "sys.path.append(str(package_root))\n",
    "\n",
    "# reusable parameters\n",
    "dataset_name = 'CIFAR10'\n",
    "data_root = Path.cwd().parent / 'data'\n",
    "\n",
    "# import everything except architectures\n",
    "from src import prepare_datasets, ModelTrainer, accuracy, MetricsPlotter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import MultiStepLR, OneCycleLR, StepLR\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=160, scale=(0.6, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize(200),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "trainset, valset, testset = prepare_datasets(\n",
    "    dataset_name=dataset_name, \n",
    "    data_root=data_root,\n",
    "    transform_train=transform_train,\n",
    "    transform_val=transform_val,\n",
    "    normalize=False,\n",
    "    use_validation_split=True,\n",
    ")\n",
    "\n",
    "model3 = EfficientNet.from_pretrained('efficientnet-b4', num_classes=10)\n",
    "\n",
    "optimizer = SGD(\n",
    "    model3.parameters(),\n",
    "    lr=0.01,\n",
    "    momentum=0.9,\n",
    "    weight_decay=1e-6\n",
    ")\n",
    "\n",
    "scheduler = StepLR(\n",
    "    optimizer,\n",
    "    step_size=10,\n",
    "    gamma=0.1\n",
    ")\n",
    "\n",
    "trainer3 = ModelTrainer(\n",
    "    model=model3,\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    loss_fn=nn.CrossEntropyLoss(),\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    batch_size=32,\n",
    "    verbose=True,\n",
    "    save_metrics=False,\n",
    "    early_stopping_patience=3,\n",
    "    metrics=[accuracy],\n",
    "    log_dir=\"logs/EfficientNet\",\n",
    "    logger_type=\"file\",\n",
    ")\n",
    "\n",
    "trained_model3 = trainer3.train(\n",
    "    training_set=trainset,\n",
    "    val_set=valset,\n",
    "    num_epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_efficientnet = trainer3.evaluate_on_test(test_set=testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Analysis\n",
    "\n",
    "After epoch 12, the model stops improving, as can be seen in the loss curves and logs. It also doesn't overfit at all; it just stays at the converged level without diverging. This is a good sign, indicating that it's tuned to perfection and the representation capacity is optimal. Worth mentioning is that training a single epoch takes as long as 20 epochs of my previous model.\n",
    "\n",
    "#### Class Accuracies\n",
    "\n",
    "It's interesting to see that the fine-tuned EfficientNet-B4 model has effectively eliminated any issues with classifying birds relative to other classes. However, as previously pointed out, it still struggles somewhat with dogs and especially cats.\n",
    "\n",
    "#### Confusion Matrix\n",
    "\n",
    "The confusion matrix confirms these observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels_efficientnet = test_results_efficientnet['true_labels']\n",
    "predictions_efficientnet = test_results_efficientnet['predictions']\n",
    "\n",
    "ax = plotter.plot_class_accuracy(true_labels_efficientnet, predictions_efficientnet, testset.classes, dataset_name=\"CIFAR-10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plotter.plot_confusion_matrix(\n",
    "    predictions=predictions_efficientnet,\n",
    "    true_labels=true_labels_efficientnet,\n",
    "    class_names=testset.classes,\n",
    "    dataset_name=\"CIFAR-10\",\n",
    "    normalize=True,\n",
    "    cmap='mako'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained best model and evaluate\n",
    "# checkpoint_path = \"efficientnet_cifar10.pt\"\n",
    "# trainer3.load_best_model(checkpoint_path=checkpoint_path)\n",
    "# test_results_efficientnet = trainer3.evaluate_on_test(test_set=testset, checkpoint_path=checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "It was fun to build and train these models, and I learned a lot from doing so. Still just feel like I've scratched the surface of what's possible with deep learning. I'm looking forward to learning more about the field and how to apply it in the future."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
